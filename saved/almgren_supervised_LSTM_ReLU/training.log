
+---------------------------+---------------------------+
| Training Configuration    |                           |
+---------------------------+---------------------------+
| Epochs                    | 1000                      |
| Learning Rate             | 0.001                     |
| Adaptive LR               | True                      |
| lambda_Y (Y loss)         | 1                         |
| lambda_T (Terminal loss)  | 1                         |
| lambda_TG (Gradient loss) | 1                         |
| Number of Paths           | 1024                      |
| Batch Size                | 1024                      |
| Architecture              | LSTM                      |
| Depth                     | 5                         |
| Width                     | 256                       |
| Activation                | ReLU                      |
| T                         | 1.0                       |
| N                         | 40                        |
| Supervised                | True                      |
+---------------------------+---------------------------+

   Epoch |   Total loss |       Y loss |      T. loss |    T.G. loss |         LR |  Memory [MB] |   Time [s] | Status
------------------------------------------------------------------------------------------------------------------------
       0 |     1.098514 |     1.098514 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       0.40 | Model saved (best)
      50 |     1.556097 |     1.556097 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.89 | Model saved \u2193
     100 |     0.799115 |     0.799115 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.97 | Model saved (best)
     150 |     0.596720 |     0.596720 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.97 | Model saved (best)
     200 |     0.829729 |     0.829729 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.63 | Model saved \u2193
     250 |     0.629007 |     0.629007 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.82 | Model saved \u2193
     300 |     0.578216 |     0.578216 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.90 | Model saved (best)
     350 |     0.658249 |     0.658249 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       2.07 | Model saved \u2193
     400 |     0.714069 |     0.714069 |     0.000000 |     0.000000 |   1.00e-03 |        63.91 |       1.77 | Model saved \u2193
     450 |     0.776435 |     0.776435 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.80 | Model saved \u2193
     500 |     0.550102 |     0.550102 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.87 | Model saved (best)
     550 |     0.587414 |     0.587414 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.99 | Model saved \u2193
     600 |     0.491460 |     0.491460 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.91 | Model saved (best)
     650 |     0.709044 |     0.709044 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.86 | Model saved \u2193
     700 |     0.608057 |     0.608057 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       2.27 | Model saved \u2193
     750 |     0.463371 |     0.463371 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       2.03 | Model saved (best)
     800 |     0.828196 |     0.828196 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       2.08 | Model saved \u2193
     850 |     0.424230 |     0.424230 |     0.000000 |     0.000000 |   8.00e-04 |        63.91 |       1.96 | Model saved (best)
     900 |     0.487126 |     0.487126 |     0.000000 |     0.000000 |   6.40e-04 |        63.91 |       1.78 | Model saved \u2193
     950 |     0.699383 |     0.699383 |     0.000000 |     0.000000 |   6.40e-04 |        63.91 |       2.03 | Model saved \u2193
     999 |     0.396492 |     0.396492 |     0.000000 |     0.000000 |   6.40e-04 |        63.91 |       1.86 | Model saved (best)
------------------------------------------------------------------------------------------------------------------------
Training completed. Lowest loss: 0.396492. Total time: 39.34 seconds
Model saved to saved/almgren_supervised_LSTM_ReLU\model.pth
